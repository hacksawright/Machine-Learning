# Untitled

# ğŸ“˜ Dá»± Ã¡n: MÃ´ hÃ¬nh Transformer huáº¥n luyá»‡n trÃªn táº­p Tiny Shakespeare

## ğŸ¯ Giá»›i thiá»‡u

Dá»± Ã¡n nÃ y xÃ¢y dá»±ng vÃ  huáº¥n luyá»‡n má»™t **mÃ´ hÃ¬nh ngÃ´n ngá»¯ Transformer (Decoder-only)** trÃªn táº­p dá»¯ liá»‡u **Tiny Shakespeare** â€“ bá»™ vÄƒn báº£n gá»“m khoáº£ng **1 triá»‡u kÃ½ tá»±** trÃ­ch tá»« cÃ¡c tÃ¡c pháº©m ná»•i tiáº¿ng cá»§a William Shakespeare (nhÆ° *Hamlet*, *Macbeth*, *Julius Caesar*, *The Tempest*, v.v.).

Má»¥c tiÃªu chÃ­nh lÃ  **huáº¥n luyá»‡n mÃ´ hÃ¬nh sinh vÄƒn báº£n** theo phong cÃ¡ch Shakespeare, thÃ´ng qua viá»‡c:

- Token hÃ³a dá»¯ liá»‡u báº±ng **SentencePiece (Byte Pair Encoding - BPE)**
- Thiáº¿t káº¿ mÃ´ hÃ¬nh Transformer tá»± cÃ i Ä‘áº·t báº±ng **PyTorch**
- Huáº¥n luyá»‡n mÃ´ hÃ¬nh trÃªn táº­p dá»¯ liá»‡u vÄƒn báº£n
- Sinh ra cÃ¡c Ä‘oáº¡n vÄƒn má»›i cÃ³ cáº¥u trÃºc vÃ  ngá»¯ Ä‘iá»‡u tÆ°Æ¡ng tá»± Shakespeare

---

## ğŸ“‚ Dá»¯ liá»‡u sá»­ dá»¥ng

### ğŸ§¾ Nguá»“n dá»¯ liá»‡u

Dá»¯ liá»‡u Ä‘Æ°á»£c táº£i trá»±c tiáº¿p tá»«:

```
https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt

```

Táº­p dá»¯ liá»‡u gá»“m:

- Khoáº£ng **1,118,394 kÃ½ tá»±**
- ToÃ n bá»™ vÄƒn báº£n lÃ  tiáº¿ng Anh cá»•, khÃ´ng cÃ³ nhÃ£n phÃ¢n loáº¡i
- ÄÆ°á»£c xá»­ lÃ½ dÆ°á»›i dáº¡ng chuá»—i kÃ½ tá»± liÃªn tá»¥c (character-level text)

### ğŸ” Äáº·c Ä‘iá»ƒm dá»¯ liá»‡u

- Dá»¯ liá»‡u cÃ³ **phong cÃ¡ch vÄƒn há»c cá»• Ä‘iá»ƒn**, giÃ u cáº¥u trÃºc ngÃ´n ngá»¯ vÃ  dáº¥u cÃ¢u.
- KhÃ´ng cÃ³ phÃ¢n chia theo cÃ¢u chuyá»‡n â€“ chá»‰ lÃ  chuá»—i kÃ½ tá»± ghÃ©p ná»‘i.
- ÄÆ°á»£c token hÃ³a báº±ng **SentencePiece (BPE)** vá»›i `vocab_size = 8000`.
- Tá»‡p mÃ´ hÃ¬nh tokenizer Ä‘Æ°á»£c lÆ°u dÆ°á»›i dáº¡ng `tinyshakespeare.model` vÃ  `tinyshakespeare.vocab`.

---

## âš™ï¸ Quy trÃ¬nh xá»­ lÃ½ vÃ  mÃ´ hÃ¬nh

### 1. **Tiá»n xá»­ lÃ½ vÃ  Tokenization**

- ToÃ n bá»™ vÄƒn báº£n Ä‘Æ°á»£c ná»‘i láº¡i thÃ nh má»™t chuá»—i duy nháº¥t.
- DÃ¹ng `SentencePieceTrainer` Ä‘á»ƒ huáº¥n luyá»‡n tokenizer vá»›i tham sá»‘:
    
    ```python
    vocab_size = 8000
    character_coverage = 1.0
    model_type = "bpe"
    
    ```
    
- Táº¡o lá»›p `TinyShakespeareData` káº¿ thá»«a `torch.utils.data.Dataset`,
    
    cÃ³ chá»©c nÄƒng:
    
    - MÃ£ hÃ³a vÄƒn báº£n thÃ nh ID (`encode_as_ids`)
    - ThÃªm token BOS/EOS
    - Tá»± Ä‘á»™ng padding batch báº±ng `collate_function`

### 2. **MÃ´ hÃ¬nh Transformer**

- Kiáº¿n trÃºc **Decoder-only Transformer**, tÆ°Æ¡ng tá»± GPT nhá» gá»n.
- CÃ¡c thÃ nh pháº§n chÃ­nh:
    - `PositionalEncoding` â€“ mÃ£ hÃ³a vá»‹ trÃ­ báº±ng hÃ m sin vÃ  cos.
    - `MultiHeadAttention` â€“ tÃ­nh toÃ¡n attention giá»¯a cÃ¡c token.
    - `FeedForward` â€“ lá»›p tuyáº¿n tÃ­nh vÃ  kÃ­ch hoáº¡t phi tuyáº¿n.
    - `TransformerBlock` â€“ tá»• há»£p cá»§a attention + feedforward + residual connection.
    - `TransformerModel` â€“ nhiá»u khá»‘i ghÃ©p ná»‘i + embedding Ä‘áº§u vÃ o + lá»›p Ä‘áº§u ra softmax.

### 3. **Huáº¥n luyá»‡n**

- Loss function: `CrossEntropyLoss`
- Optimizer: `Adam`
- Huáº¥n luyá»‡n trÃªn táº­p dá»¯ liá»‡u Ä‘Æ°á»£c tokenize, batch-size nhá» (do tÃ­nh cháº¥t ngÃ´n ngá»¯ tá»± nhiÃªn).
- Má»¥c tiÃªu: mÃ´ hÃ¬nh há»c cÃ¡ch **dá»± Ä‘oÃ¡n token tiáº¿p theo** dá»±a trÃªn chuá»—i token trÆ°á»›c Ä‘Ã³.

---

## ğŸ§  Äiá»ƒm ná»•i báº­t trong triá»ƒn khai

- **Tá»± cÃ i Ä‘áº·t mÃ´ hÃ¬nh Transformer tá»« Ä‘áº§u** (khÃ´ng dÃ¹ng `nn.Transformer` cá»§a PyTorch).
- **Huáº¥n luyá»‡n tokenizer BPE** riÃªng cho dá»¯ liá»‡u vÄƒn há»c Shakespeare.
- Thiáº¿t káº¿ **Dataset + DataLoader** tÃ¹y chá»‰nh giÃºp Ä‘á»c dá»¯ liá»‡u hiá»‡u quáº£.
- CÃ³ thá»ƒ **sinh vÄƒn báº£n má»›i** báº±ng cÃ¡ch:
    
    ```python
    model.generate(prompt="ROMEO:", max_length=100)
    
    ```
    
- MÃ£ nguá»“n rÃµ rÃ ng, tÃ¡ch biá»‡t tá»«ng pháº§n: tiá»n xá»­ lÃ½ â€“ mÃ´ hÃ¬nh â€“ huáº¥n luyá»‡n â€“ sinh vÄƒn báº£n.

---

## ğŸ“Š Káº¿t quáº£ Ä‘áº¡t Ä‘Æ°á»£c

- MÃ´ hÃ¬nh sau khi huáº¥n luyá»‡n cÃ³ kháº£ nÄƒng sinh ra cÃ¡c Ä‘oáº¡n vÄƒn cÃ³ cÃº phÃ¡p, dáº¥u cÃ¢u, vÃ  nhá»‹p Ä‘iá»‡u **giá»‘ng phong cÃ¡ch Shakespeare**.
- CÃ¡c cÃ¢u Ä‘áº§u ra cÃ³ dáº¡ng:
    
    ```
    ROMEO:
    O, speak again, bright angel! for thou art
    As glorious to this night, being oâ€™er my head...
    
    ```
    
- Tokenizer hoáº¡t Ä‘á»™ng hiá»‡u quáº£, tÃ¡i táº¡o chÃ­nh xÃ¡c cáº¥u trÃºc ngÃ´n ngá»¯.
- Transformer há»™i tá»¥ á»•n Ä‘á»‹nh sau má»™t sá»‘ epoch huáº¥n luyá»‡n, loss giáº£m Ä‘á»u.

---

## ğŸš€ CÃ¡ch cháº¡y notebook

1. CÃ i Ä‘áº·t thÆ° viá»‡n cáº§n thiáº¿t:
    
    ```bash
    pip install torch datasets sentencepiece tqdm
    
    ```
    
2. Má»Ÿ file notebook trong Jupyter hoáº·c Colab.
3. Cháº¡y toÃ n bá»™ cell Ä‘á»ƒ:
    - Táº£i dá»¯ liá»‡u vÃ  huáº¥n luyá»‡n tokenizer.
    - XÃ¢y dá»±ng mÃ´ hÃ¬nh Transformer.
    - Huáº¥n luyá»‡n mÃ´ hÃ¬nh.
    - Sinh thá»­ vÄƒn báº£n má»›i.

---

## ğŸ§¾ Tá»•ng káº¿t

Dá»± Ã¡n minh há»a má»™t vÃ­ dá»¥ **Ä‘iá»ƒn hÃ¬nh vá» mÃ´ hÃ¬nh ngÃ´n ngá»¯ tá»± triá»ƒn khai (custom Transformer)** trÃªn má»™t táº­p dá»¯ liá»‡u cá»• Ä‘iá»ƒn â€“ Tiny Shakespeare.

ToÃ n bá»™ quy trÃ¬nh tá»« **tokenization â†’ modeling â†’ training â†’ text generation** Ä‘á»u Ä‘Æ°á»£c thá»±c hiá»‡n thá»§ cÃ´ng, giÃºp hiá»ƒu rÃµ cÆ¡ cháº¿ hoáº¡t Ä‘á»™ng bÃªn trong cá»§a mÃ´ hÃ¬nh Transformer.

Káº¿t quáº£ cho tháº¥y, vá»›i cáº¥u hÃ¬nh phÃ¹ há»£p vÃ  dá»¯ liá»‡u nhá», mÃ´ hÃ¬nh váº«n cÃ³ thá»ƒ **há»c Ä‘Æ°á»£c phong cÃ¡ch ngÃ´n ngá»¯ tá»± nhiÃªn** vÃ  táº¡o ra vÄƒn báº£n cÃ³ **tÃ­nh vÄƒn há»c vÃ  máº¡ch láº¡c cao**.